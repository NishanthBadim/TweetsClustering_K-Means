# -*- coding: utf-8 -*-
"""NXB220044_Assignment3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yM-wiVlx0td1cDXUgKegpZCZXeVLwRI5
"""

import numpy as np
import random
import math
import pandas as pd

df = pd.read_csv("https://raw.githubusercontent.com/NishanthBadim/TweetsClustering_K-Means/main/bbchealth.txt",names=['tweet_id', 'data_time', 'tweet'],sep="|",error_bad_lines=False)

class Kmeans:
    def __init__(self, data, num_clusters, max_iterations=100, lr=1e-4):
        self.num_clusters = num_clusters
        self.iterations = max_iterations
        self.lr = lr
        self.data = self.preprocess(data)

    def preprocess(self,data):
        #Removal the tweet id and timestamp
        preprocessed_data = data.drop(data.columns[[0, 1]], axis=1)
        #Removal of any word that starts with the symbol @
        preprocessed_data['tweet'] = preprocessed_data['tweet'].str.replace('(@\w+.*?)', "")
        #Removal of any hashtag symbols
        preprocessed_data['tweet'] = preprocessed_data['tweet'].replace({'#': ''}, regex=True)
        #Removal of any URL
        preprocessed_data['tweet'] = preprocessed_data['tweet'].str.rsplit('http').str[0]
        #Conversion of uppercase letters to lower case
        preprocessed_data['tweet'] = preprocessed_data['tweet'].str.lower()

        return preprocessed_data['tweet'].tolist()


    def jaccard_distance(self, tweet1, tweet2):
        #followed the formula given in description
        tweet1_set = set(tweet1.split())
        tweet2_set = set(tweet2.split())
        # intersection
        intersection_words = len(tweet1_set.intersection(tweet2_set))
        # union
        union_words = len(tweet1_set.union(tweet2_set))
        return 1.0 - (intersection_words / union_words)


    def check_centroids(self, new_centroids, prev_centroids):
      # check for change between prevoius and new centroids
      if len(new_centroids) != len(prev_centroids):
          return 0
      for i in range(len(new_centroids)):
          if " ".join(prev_centroids[i]) != " ".join(new_centroids[i]):
              return 0
      return 1


    def recompute_centroids(self, clusters):
        # List to store updated centroids
        centroids = []

        # Iterate over each cluster
        for cluster in range(len(clusters)):
            # Variable to track the total minimum distance
            total_minimum_distance = math.inf

            # Matrix to store minimum distances
            matrix_minimum_distance = np.zeros((len(clusters[cluster]), len(clusters[cluster])))

            # Iterate over each tweet in the cluster
            for i in range(len(clusters[cluster])):
                total_distance = 0

                # Compare each tweet with every other tweet in the cluster
                for j in range(len(clusters[cluster])):
                    # Skip comparison with itself
                    if i != j:
                        # Check if the distance is already computed
                        if matrix_minimum_distance[i][j] != 0:
                            distance = matrix_minimum_distance[i][j]
                        else:
                            # If not computed, calculate and store the distance
                            if clusters[cluster][i] == "" or clusters[cluster][j] == "":
                                continue
                            distance = self.jaccard_distance(clusters[cluster][i], clusters[cluster][j])
                            matrix_minimum_distance[i][j] = distance

                        total_distance += distance

                # Update centroid if the total distance is less than the current minimum
                if total_distance < total_minimum_distance:
                    total_minimum_distance = total_distance
                    centroid_id = i

            # Append the tweet corresponding to the updated centroid
            centroids.append(clusters[cluster][centroid_id])

        # Return the list of updated centroids
        return centroids



    def predict(self, tweets):
        clusters = [[] for _ in range(len(self.centroids))]

        # Iterate over each tweet
        for tweet in tweets:
            # Initialize minimum distance to infinity
            minimum_distance = math.inf
            centroid_id = -1

            for idx, centroid in enumerate(self.centroids):

                # Calculate the distance between tweet and centroid
                tweet_centroid_distance = self.jaccard_distance(tweet, centroid)

                # Re-Initialize minimum distance appropriately
                if tweet_centroid_distance < minimum_distance:
                    minimum_distance = tweet_centroid_distance
                    centroid_id = idx

            # Assign nearest tweet to it's cluster
            clusters[centroid_id].append(tweet)

        return clusters


    def fit(self):
        random.seed(10)
        self.tweets = self.data

        #intializing random tweets as centroids
        self.centroids =  random.sample(self.tweets, self.num_clusters)

        for _ in range(self.iterations):
            prev_centroids = np.copy(self.centroids)
            # Assigning tweet to it's cluster
            clusters = self.predict(self.tweets)
            # Re-computing centroids
            self.centroids=self.recompute_centroids(clusters)
            # Checking for change in centroids
            if(self.check_centroids(self.centroids, prev_centroids)):
              break

        # Calculate the Sum of Squared Error
        sse = self.compute_sse(clusters,self.centroids)
        print("Sum of Squared Error",sse)
        for i in range(self.num_clusters):
            print("Cluster ", i+1, ":", len(clusters[i]),"tweets")


    def compute_sse(self,clusters,centroids):
      sse_value = 0
      for i in range(len(clusters)):
          for j in range(len(clusters[i])):
            dist=self.jaccard_distance(centroids[i],clusters[i][j])
            sse_value = sse_value + pow(dist,2)
      return sse_value

if __name__ == "__main__":
    k_clusters= [2, 5, 10, 12, 18, 20, 30, 40, 50, 75, 100]
    for k in k_clusters:
      print("Value of K : ", k)
      k_means = Kmeans(df, num_clusters = k)
      k_means.fit()

